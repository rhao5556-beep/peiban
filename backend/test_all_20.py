"""
å®Œæ•´çš„ 20 æ¡æµ‹è¯•ç”¨ä¾‹ - è¦†ç›–å…¨éƒ¨ä¹ä¸ªéƒ¨åˆ†
"""
import requests
import json
import time

API_BASE = "http://localhost:8000/api/v1"
USER_ID = "9a9e9803-94d6-4ecd-8d09-66fb4745ef85"

def get_token():
    r = requests.post(f"{API_BASE}/auth/token", json={"user_id": USER_ID})
    return r.json()["access_token"]

def send_message(text):
    token = get_token()
    resp = requests.post(
        f"{API_BASE}/sse/message",
        json={"message": text},
        headers={"Authorization": f"Bearer {token}"},
        stream=True
    )
    
    memory_id = None
    ai_response = ""
    for line in resp.iter_lines():
        if line:
            line_str = line.decode('utf-8')
            if line_str.startswith('data: '):
                data_str = line_str[6:]
                if data_str == '[DONE]':
                    break
                try:
                    event = json.loads(data_str)
                    if event.get('type') == 'text':
                        ai_response += event.get('content', '')
                    elif event.get('type') == 'memory_pending':
                        memory_id = event.get('memory_id')
                except:
                    pass
    return memory_id, ai_response

def wait_commit(memory_id, timeout=45):
    if not memory_id:
        return False
    token = get_token()
    start = time.time()
    while time.time() - start < timeout:
        try:
            resp = requests.get(
                f"{API_BASE}/memories/{memory_id}",
                headers={"Authorization": f"Bearer {token}"}
            )
            if resp.status_code == 200:
                status = resp.json().get("status")
                if status == "committed":
                    return True
                elif status == "pending_review":
                    return "pending_review"
        except:
            pass
        time.sleep(2)
    return False

def get_graph():
    token = get_token()
    resp = requests.get(f"{API_BASE}/graph/", headers={"Authorization": f"Bearer {token}"})
    return resp.json()

def run_test(test_id, category, text, expected, notes=""):
    print(f"\n{'='*60}")
    print(f"æµ‹è¯• #{test_id} [{category}]")
    print(f"è¾“å…¥: {text}")
    if notes:
        print(f"å¤‡æ³¨: {notes}")
    print(f"æœŸæœ›: {expected}")
    print(f"{'='*60}")
    
    # è·å–æµ‹è¯•å‰å›¾è°±
    graph_before = get_graph()
    nodes_before = set(n['id'] for n in graph_before['nodes'])
    edges_before = set(f"{e['source_id']}->{e['target_id']}" for e in graph_before['edges'])
    
    # å‘é€æ¶ˆæ¯
    memory_id, ai_response = send_message(text)
    print(f"ğŸ“¤ æ¶ˆæ¯å·²å‘é€")
    print(f"ğŸ’¬ AI: {ai_response[:80]}..." if len(ai_response) > 80 else f"ğŸ’¬ AI: {ai_response}")
    
    if memory_id:
        print(f"ğŸ”„ ç­‰å¾…æäº¤ (id: {memory_id[:16]}...)...")
        result = wait_commit(memory_id, timeout=45)
        if result == True:
            print(f"âœ… å·²æäº¤")
        elif result == "pending_review":
            print(f"âš ï¸ è¿›å…¥ pending_reviewï¼ˆç¬¦åˆé¢„æœŸï¼‰")
        else:
            print(f"âš ï¸ è¶…æ—¶")
            time.sleep(5)
    else:
        print(f"â„¹ï¸ æ—  Memory")
        time.sleep(3)
    
    # è·å–æµ‹è¯•åå›¾è°±
    graph_after = get_graph()
    nodes_after = set(n['id'] for n in graph_after['nodes'])
    edges_after = set(f"{e['source_id']}->{e['target_id']}" for e in graph_after['edges'])
    
    # æ–°å¢å†…å®¹
    new_nodes = nodes_after - nodes_before
    new_edges = edges_after - edges_before
    
    node_map = {n['id']: n['name'] for n in graph_after['nodes']}
    
    print(f"\nğŸ“Š ç»“æœ:")
    print(f"  æ–°å¢èŠ‚ç‚¹: {len(new_nodes)}")
    for nid in new_nodes:
        n = next((x for x in graph_after['nodes'] if x['id'] == nid), None)
        if n:
            print(f"    - {n['name']} ({n['type']})")
    
    print(f"  æ–°å¢å…³ç³»: {len(new_edges)}")
    for eid in new_edges:
        e = next((x for x in graph_after['edges'] if f"{x['source_id']}->{x['target_id']}" == eid), None)
        if e:
            src = node_map.get(e['source_id'], e['source_id'][:8])
            tgt = node_map.get(e['target_id'], e['target_id'][:8])
            print(f"    - {src} --[{e['relation_type']}]--> {tgt}")
    
    return {
        "test_id": test_id,
        "new_nodes": len(new_nodes),
        "new_edges": len(new_edges)
    }

# ============================================================================
# å®Œæ•´ 20 æ¡æµ‹è¯•ç”¨ä¾‹ - ä¹ä¸ªéƒ¨åˆ†
# ============================================================================

ALL_TESTS = [
    # ========== ä¸€ã€åŸºç¡€å®ä½“ + User â†’ Entityï¼ˆçƒ­èº«ï¼‰==========
    ("1", "ä¸€ã€åŸºç¡€å®ä½“", "äºŒä¸«æ˜¯æˆ‘æœ‹å‹",
     "Entity: äºŒä¸«(Person), Relation: user â†’ FRIEND_OF â†’ äºŒä¸«", ""),
    
    ("2", "ä¸€ã€åŸºç¡€å®ä½“", "æˆ‘ä½åœ¨å“ˆå°”æ»¨",
     "Entity: å“ˆå°”æ»¨(Location), Relation: user â†’ LIVES_IN â†’ å“ˆå°”æ»¨", ""),
    
    ("3", "ä¸€ã€åŸºç¡€å®ä½“", "å¼ ä¼Ÿæ˜¯æˆ‘åŒäº‹",
     "Entity: å¼ ä¼Ÿ(Person), Relation: user â†’ COLLEAGUE_OF â†’ å¼ ä¼Ÿ", ""),
    
    # ========== äºŒã€Entity â†’ Entityï¼ˆæ ¸å¿ƒèƒ½åŠ›ï¼‰==========
    ("4", "äºŒã€Entityâ†’Entity", "äºŒä¸«å–œæ¬¢ç¯®çƒ",
     "Entity: äºŒä¸«, ç¯®çƒ, Relation: äºŒä¸« â†’ LIKES â†’ ç¯®çƒ", "âš ï¸ æ­£åˆ™å¿…æŒ‚ï¼ŒLLM å¿…é¡»æˆåŠŸ"),
    
    ("5", "äºŒã€Entityâ†’Entity", "å¼ ä¼Ÿå’ŒäºŒä¸«æ˜¯å¤§å­¦åŒå­¦",
     "Relation: å¼ ä¼Ÿ â†” CLASSMATE_OF â†” äºŒä¸«", ""),
    
    ("6", "äºŒã€Entityâ†’Entity", "æˆ‘æœ‹å‹äºŒä¸«åœ¨åŒ—äº¬å·¥ä½œ",
     "user â†’ FRIEND_OF â†’ äºŒä¸«, äºŒä¸« â†’ WORKS_IN â†’ åŒ—äº¬", ""),
    
    # ========== ä¸‰ã€æ˜µç§° / é"æˆ‘çš„"å‰ç¼€ï¼ˆæ­£åˆ™æ­»åŒºï¼‰==========
    ("7", "ä¸‰ã€æ˜µç§°è¯†åˆ«", "æ˜Šå“¥æœ€è¿‘å¾ˆå¿™",
     "Entity: æ˜Šå“¥(Person)", "è‡³å°‘è¦å»ºå®ä½“"),
    
    ("8", "ä¸‰ã€æ˜µç§°è¯†åˆ«", "å¼ sirä»Šå¤©å¿ƒæƒ…ä¸é”™",
     "Entity: å¼ sir(Person)", "å¯å¤ç”¨ recent_entities ä¸­çš„å¼ ä¼Ÿ"),
    
    # ========== å››ã€recent_entities æ¶ˆæ­§æµ‹è¯• ==========
    ("9", "å››ã€è¯­ä¹‰ç†è§£", "äºŒä¸«å…¶å®å°±æ˜¯å¼ ä¼Ÿçš„å¦¹å¦¹",
     "Relation: äºŒä¸« â†’ SIBLING_OF â†’ å¼ ä¼Ÿ", "âš ï¸ å¼ºè¯­ä¹‰ç†è§£"),
    
    ("10", "å››ã€å®ä½“æ¶ˆæ­§", "äºŒä¸«æœ€è¿‘æ¢å·¥ä½œäº†",
     "å¿…é¡»å¤ç”¨å·²æœ‰ idï¼Œä¸å…è®¸æ–°å»º", ""),
    
    ("11", "å››ã€æŒ‡ä»£æ¶ˆè§£", "å¥¹æœ€è¿‘å‹åŠ›å¾ˆå¤§",
     "'å¥¹'æŒ‡ä»£æœ€è¿‘æ´»è·ƒå®ä½“ï¼ˆäºŒä¸«ï¼‰", ""),
    
    # ========== äº”ã€å¤šå¥ / è·¨å¥ä¸Šä¸‹æ–‡ ==========
    ("12", "äº”ã€è·¨å¥ç†è§£", "æˆ‘æœ‰ä¸ªæœ‹å‹å«äºŒä¸« å¥¹å¾ˆå–œæ¬¢æ‰“ç¯®çƒ",
     "user â†’ FRIEND_OF â†’ äºŒä¸«, äºŒä¸« â†’ LIKES â†’ ç¯®çƒ", ""),
    
    ("13", "äº”ã€è·¨å¥ç†è§£", "å¼ ä¼Ÿæ˜¯æˆ‘åŒäº‹ ä»–å’ŒäºŒä¸«å…³ç³»å¾ˆå¥½",
     "user â†’ COLLEAGUE â†’ å¼ ä¼Ÿ, å¼ ä¼Ÿ â†’ HAS_GOOD_RELATION â†’ äºŒä¸«", ""),
    
    # ========== å…­ã€å¦å®š / ä¿®æ­£è¯­ä¹‰ï¼ˆLLM ä¼˜åŠ¿åŒºï¼‰==========
    ("14", "å…­ã€å¦å®šè¯­ä¹‰", "äºŒä¸«ä¸æ˜¯æˆ‘åŒäº‹ï¼Œæ˜¯æˆ‘è¡¨å¦¹",
     "user â†’ COUSIN_OF â†’ äºŒä¸«", "ä¸åº”ä¿ç•™'åŒäº‹'å…³ç³»"),
    
    ("15", "å…­ã€å¦å®šè¯­ä¹‰", "æˆ‘ä¸å¤ªå–œæ¬¢ç¯®çƒï¼Œä½†äºŒä¸«å¾ˆå–œæ¬¢",
     "user â†’ DISLIKES â†’ ç¯®çƒ, äºŒä¸« â†’ LIKES â†’ ç¯®çƒ", ""),
    
    # ========== ä¸ƒã€æ¨¡ç³Š / æ¨æ–­å‹å…³ç³» ==========
    ("16", "ä¸ƒã€æ¨æ–­å…³ç³»", "äºŒä¸«ç»å¸¸åŠ ç­ï¼Œçœ‹èµ·æ¥å·¥ä½œå‹åŠ›ä¸å°",
     "äºŒä¸« â†’ HAS_STATE â†’ å·¥ä½œå‹åŠ›å¤§", "å…è®¸ confidence < 1.0"),
    
    ("17", "ä¸ƒã€æ¨æ–­å…³ç³»", "å¼ ä¼Ÿå¥½åƒåœ¨ä¸Šæµ·å‘å±•",
     "å¼ ä¼Ÿ â†’ PROBABLY_WORKS_IN â†’ ä¸Šæµ·", "metadata.confidence < 1.0"),
    
    # ========== å…«ã€å¼‚å¸¸ / å¤±è´¥è·¯å¾„æµ‹è¯•ï¼ˆéå¸¸å…³é”®ï¼‰==========
    # æ³¨æ„ï¼š18ã€19 éœ€è¦ç‰¹æ®Šå¤„ç†ï¼Œè¿™é‡Œç”¨æ­£å¸¸æ¶ˆæ¯æ¨¡æ‹Ÿ
    ("18", "å…«ã€å¼‚å¸¸æµ‹è¯•", "asdfghjkl123456",
     "âŒ ä¸å†™å…¥ Neo4j, âœ… æ ‡è®° pending_review", "æ¨¡æ‹Ÿæ— æ„ä¹‰è¾“å…¥"),
    
    ("19", "å…«ã€å¼‚å¸¸æµ‹è¯•", "!@#$%^&*()",
     "âŒ ä¸å†™å…¥ Neo4j, âœ… æ ‡è®° pending_review", "æ¨¡æ‹Ÿç‰¹æ®Šå­—ç¬¦"),
    
    # ========== ä¹ã€å¤åˆä¸–ç•Œè§‚æ„å»ºï¼ˆç»ˆææµ‹è¯•ï¼‰==========
    ("20", "ä¹ã€å¤åˆæµ‹è¯•", "äºŒä¸«æ˜¯æˆ‘æœ‹å‹ï¼Œå¥¹å–œæ¬¢ç¯®çƒï¼Œä¹Ÿå’Œå¼ ä¼Ÿæ˜¯å¤§å­¦åŒå­¦ï¼Œç°åœ¨åœ¨åŒ—äº¬å·¥ä½œ",
     "userâ†’FRIEND_OFâ†’äºŒä¸«, äºŒä¸«â†’LIKESâ†’ç¯®çƒ, äºŒä¸«â†”CLASSMATE_OFâ†”å¼ ä¼Ÿ, äºŒä¸«â†’WORKS_ATâ†’åŒ—äº¬",
     "ç»ˆææµ‹è¯•ï¼šå¤šå®ä½“å¤šå…³ç³»"),
]

if __name__ == "__main__":
    print("=" * 70)
    print("ğŸ§ª å®Œæ•´ 20 æ¡æµ‹è¯•ç”¨ä¾‹ - è¦†ç›–å…¨éƒ¨ä¹ä¸ªéƒ¨åˆ†")
    print("=" * 70)
    print("""
    ä¸€ã€åŸºç¡€å®ä½“ + User â†’ Entityï¼ˆ1-3ï¼‰
    äºŒã€Entity â†’ Entityï¼ˆ4-6ï¼‰
    ä¸‰ã€æ˜µç§° / é"æˆ‘çš„"å‰ç¼€ï¼ˆ7-8ï¼‰
    å››ã€recent_entities æ¶ˆæ­§æµ‹è¯•ï¼ˆ9-11ï¼‰
    äº”ã€å¤šå¥ / è·¨å¥ä¸Šä¸‹æ–‡ï¼ˆ12-13ï¼‰
    å…­ã€å¦å®š / ä¿®æ­£è¯­ä¹‰ï¼ˆ14-15ï¼‰
    ä¸ƒã€æ¨¡ç³Š / æ¨æ–­å‹å…³ç³»ï¼ˆ16-17ï¼‰
    å…«ã€å¼‚å¸¸ / å¤±è´¥è·¯å¾„æµ‹è¯•ï¼ˆ18-19ï¼‰
    ä¹ã€å¤åˆä¸–ç•Œè§‚æ„å»ºï¼ˆ20ï¼‰
    """)
    
    results = []
    for test_id, category, text, expected, notes in ALL_TESTS:
        try:
            result = run_test(test_id, category, text, expected, notes)
            results.append(result)
        except Exception as e:
            print(f"âŒ æµ‹è¯• #{test_id} å¤±è´¥: {e}")
        
        time.sleep(3)  # æµ‹è¯•é—´éš”
    
    # æœ€ç»ˆå›¾è°±çŠ¶æ€
    print("\n" + "=" * 70)
    print("ğŸ“Š æœ€ç»ˆå›¾è°±çŠ¶æ€")
    print("=" * 70)
    
    graph = get_graph()
    print(f"æ€»èŠ‚ç‚¹æ•°: {len(graph['nodes'])}")
    print(f"æ€»è¾¹æ•°: {len(graph['edges'])}")
    
    print("\næ‰€æœ‰èŠ‚ç‚¹:")
    for n in graph['nodes']:
        print(f"  - {n['name']} ({n['type']})")
    
    print("\næ‰€æœ‰å…³ç³»:")
    node_map = {n['id']: n['name'] for n in graph['nodes']}
    for e in graph['edges']:
        src = node_map.get(e['source_id'], e['source_id'][:8])
        tgt = node_map.get(e['target_id'], e['target_id'][:8])
        w = e.get('current_weight') or e.get('weight', 1)
        print(f"  - {src} --[{e['relation_type']}]--> {tgt} ({w:.0%})")
    
    # ç»Ÿè®¡
    print("\n" + "=" * 70)
    print("ğŸ“ˆ æµ‹è¯•ç»Ÿè®¡")
    print("=" * 70)
    total_new_nodes = sum(r.get('new_nodes', 0) for r in results)
    total_new_edges = sum(r.get('new_edges', 0) for r in results)
    print(f"  æµ‹è¯•ç”¨ä¾‹æ•°: {len(results)}")
    print(f"  æ–°å¢èŠ‚ç‚¹æ€»æ•°: {total_new_nodes}")
    print(f"  æ–°å¢å…³ç³»æ€»æ•°: {total_new_edges}")
