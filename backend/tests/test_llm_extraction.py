"""
LLM + IR + Graph æ¶æ„éªŒè¯æµ‹è¯•
è¦†ç›–ï¼šå®ä½“æŠ½å–ã€å®ä½“æ¶ˆæ­§ã€Entityâ†’Entity å…³ç³»ã€æ˜µç§°/æŒ‡ä»£ã€å¤±è´¥å…œåº•
"""
import json
import time
import requests
from typing import Dict, List, Any, Optional
from dataclasses import dataclass

# é…ç½®
API_BASE = "http://localhost:8000/api/v1"
TOKEN = None
USER_ID = None

@dataclass
class TestCase:
    """æµ‹è¯•ç”¨ä¾‹"""
    id: str
    category: str
    input_text: str
    expected_entities: List[str]
    expected_relations: List[str]
    notes: str = ""

# ============================================================================
# 20 æ¡æµ‹è¯•ç”¨ä¾‹
# ============================================================================

TEST_CASES = [
    # ä¸€ã€åŸºç¡€å®ä½“ + User â†’ Entityï¼ˆçƒ­èº«ï¼‰
    TestCase(
        id="1", category="åŸºç¡€å®ä½“",
        input_text="äºŒä¸«æ˜¯æˆ‘æœ‹å‹",
        expected_entities=["äºŒä¸«(Person)"],
        expected_relations=["user â†’ FRIEND_OF â†’ äºŒä¸«"],
    ),
    TestCase(
        id="2", category="åŸºç¡€å®ä½“",
        input_text="æˆ‘ä½åœ¨å“ˆå°”æ»¨",
        expected_entities=["å“ˆå°”æ»¨(Location)"],
        expected_relations=["user â†’ LIVES_IN â†’ å“ˆå°”æ»¨"],
    ),
    TestCase(
        id="3", category="åŸºç¡€å®ä½“",
        input_text="å¼ ä¼Ÿæ˜¯æˆ‘åŒäº‹",
        expected_entities=["å¼ ä¼Ÿ(Person)"],
        expected_relations=["user â†’ WORKS_AT/COLLEAGUE â†’ å¼ ä¼Ÿ"],
    ),
    
    # äºŒã€Entity â†’ Entityï¼ˆæ ¸å¿ƒèƒ½åŠ›ï¼‰
    TestCase(
        id="4", category="Entityâ†’Entity",
        input_text="äºŒä¸«å–œæ¬¢ç¯®çƒ",
        expected_entities=["äºŒä¸«(Person)", "ç¯®çƒ(Preference)"],
        expected_relations=["äºŒä¸« â†’ LIKES â†’ ç¯®çƒ"],
        notes="âš ï¸ æ­£åˆ™å¿…æŒ‚ï¼ŒLLM å¿…é¡»æˆåŠŸ",
    ),
    TestCase(
        id="5", category="Entityâ†’Entity",
        input_text="å¼ ä¼Ÿå’ŒäºŒä¸«æ˜¯å¤§å­¦åŒå­¦",
        expected_entities=["å¼ ä¼Ÿ(Person)", "äºŒä¸«(Person)"],
        expected_relations=["å¼ ä¼Ÿ â†” CLASSMATE_OF â†” äºŒä¸«"],
    ),
    TestCase(
        id="6", category="Entityâ†’Entity",
        input_text="æˆ‘æœ‹å‹äºŒä¸«åœ¨åŒ—äº¬å·¥ä½œ",
        expected_entities=["äºŒä¸«(Person)", "åŒ—äº¬(Location)"],
        expected_relations=["user â†’ FRIEND_OF â†’ äºŒä¸«", "äºŒä¸« â†’ WORKS_AT â†’ åŒ—äº¬"],
    ),
    
    # ä¸‰ã€æ˜µç§° / é"æˆ‘çš„"å‰ç¼€ï¼ˆæ­£åˆ™æ­»åŒºï¼‰
    TestCase(
        id="7", category="æ˜µç§°è¯†åˆ«",
        input_text="æ˜Šå“¥æœ€è¿‘å¾ˆå¿™",
        expected_entities=["æ˜Šå“¥(Person)"],
        expected_relations=[],
        notes="è‡³å°‘è¦å»ºå®ä½“",
    ),
    TestCase(
        id="8", category="æ˜µç§°è¯†åˆ«",
        input_text="å¼ sirä»Šå¤©å¿ƒæƒ…ä¸é”™",
        expected_entities=["å¼ sir(Person)"],
        expected_relations=[],
        notes="å¯å¤ç”¨ recent_entities",
    ),
    TestCase(
        id="9", category="è¯­ä¹‰ç†è§£",
        input_text="äºŒä¸«å…¶å®å°±æ˜¯å¼ ä¼Ÿçš„å¦¹å¦¹",
        expected_entities=["äºŒä¸«(Person)", "å¼ ä¼Ÿ(Person)"],
        expected_relations=["äºŒä¸« â†’ SIBLING_OF â†’ å¼ ä¼Ÿ"],
        notes="âš ï¸ å¼ºè¯­ä¹‰ç†è§£",
    ),
    
    # å››ã€recent_entities æ¶ˆæ­§æµ‹è¯•
    TestCase(
        id="10", category="å®ä½“æ¶ˆæ­§",
        input_text="äºŒä¸«æœ€è¿‘æ¢å·¥ä½œäº†",
        expected_entities=["äºŒä¸«(Person)"],
        expected_relations=[],
        notes="å¿…é¡»å¤ç”¨å·²æœ‰ idï¼Œä¸å…è®¸æ–°å»º",
    ),
    TestCase(
        id="11", category="æŒ‡ä»£æ¶ˆè§£",
        input_text="å¥¹æœ€è¿‘å‹åŠ›å¾ˆå¤§",
        expected_entities=[],
        expected_relations=[],
        notes="'å¥¹'æŒ‡ä»£æœ€è¿‘æ´»è·ƒå®ä½“",
    ),
    
    # äº”ã€å¤šå¥ / è·¨å¥ä¸Šä¸‹æ–‡
    TestCase(
        id="12", category="è·¨å¥ç†è§£",
        input_text="æˆ‘æœ‰ä¸ªæœ‹å‹å«äºŒä¸« å¥¹å¾ˆå–œæ¬¢æ‰“ç¯®çƒ",
        expected_entities=["äºŒä¸«(Person)", "ç¯®çƒ(Preference)"],
        expected_relations=["user â†’ FRIEND_OF â†’ äºŒä¸«", "äºŒä¸« â†’ LIKES â†’ ç¯®çƒ"],
    ),
    TestCase(
        id="13", category="è·¨å¥ç†è§£",
        input_text="å¼ ä¼Ÿæ˜¯æˆ‘åŒäº‹ ä»–å’ŒäºŒä¸«å…³ç³»å¾ˆå¥½",
        expected_entities=["å¼ ä¼Ÿ(Person)", "äºŒä¸«(Person)"],
        expected_relations=["user â†’ COLLEAGUE â†’ å¼ ä¼Ÿ", "å¼ ä¼Ÿ â†’ RELATED_TO â†’ äºŒä¸«"],
    ),
    
    # å…­ã€å¦å®š / ä¿®æ­£è¯­ä¹‰
    TestCase(
        id="14", category="å¦å®šè¯­ä¹‰",
        input_text="äºŒä¸«ä¸æ˜¯æˆ‘åŒäº‹ï¼Œæ˜¯æˆ‘è¡¨å¦¹",
        expected_entities=["äºŒä¸«(Person)"],
        expected_relations=["user â†’ COUSIN_OF/FAMILY â†’ äºŒä¸«"],
        notes="ä¸åº”ä¿ç•™'åŒäº‹'å…³ç³»",
    ),
    TestCase(
        id="15", category="å¦å®šè¯­ä¹‰",
        input_text="æˆ‘ä¸å¤ªå–œæ¬¢ç¯®çƒï¼Œä½†äºŒä¸«å¾ˆå–œæ¬¢",
        expected_entities=["ç¯®çƒ(Preference)", "äºŒä¸«(Person)"],
        expected_relations=["user â†’ DISLIKES â†’ ç¯®çƒ", "äºŒä¸« â†’ LIKES â†’ ç¯®çƒ"],
    ),
    
    # ä¸ƒã€æ¨¡ç³Š / æ¨æ–­å‹å…³ç³»
    TestCase(
        id="16", category="æ¨æ–­å…³ç³»",
        input_text="äºŒä¸«ç»å¸¸åŠ ç­ï¼Œçœ‹èµ·æ¥å·¥ä½œå‹åŠ›ä¸å°",
        expected_entities=["äºŒä¸«(Person)"],
        expected_relations=[],
        notes="å…è®¸ confidence < 1.0",
    ),
    TestCase(
        id="17", category="æ¨æ–­å…³ç³»",
        input_text="å¼ ä¼Ÿå¥½åƒåœ¨ä¸Šæµ·å‘å±•",
        expected_entities=["å¼ ä¼Ÿ(Person)", "ä¸Šæµ·(Location)"],
        expected_relations=["å¼ ä¼Ÿ â†’ WORKS_AT/LIVES_IN â†’ ä¸Šæµ·"],
        notes="metadata.confidence < 1.0",
    ),
    
    # å…«ã€å¼‚å¸¸ / å¤±è´¥è·¯å¾„æµ‹è¯• - è·³è¿‡ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
    # TestCase(id="18", ...) - æ¨¡æ‹Ÿ LLM è¿”å›é JSON
    # TestCase(id="19", ...) - æ¨¡æ‹Ÿ API è¶…æ—¶
    
    # ä¹ã€å¤åˆä¸–ç•Œè§‚æ„å»ºï¼ˆç»ˆææµ‹è¯•ï¼‰
    TestCase(
        id="20", category="å¤åˆæµ‹è¯•",
        input_text="äºŒä¸«æ˜¯æˆ‘æœ‹å‹ï¼Œå¥¹å–œæ¬¢ç¯®çƒï¼Œä¹Ÿå’Œå¼ ä¼Ÿæ˜¯å¤§å­¦åŒå­¦ï¼Œç°åœ¨åœ¨åŒ—äº¬å·¥ä½œ",
        expected_entities=["äºŒä¸«(Person)", "ç¯®çƒ(Preference)", "å¼ ä¼Ÿ(Person)", "åŒ—äº¬(Location)"],
        expected_relations=[
            "user â†’ FRIEND_OF â†’ äºŒä¸«",
            "äºŒä¸« â†’ LIKES â†’ ç¯®çƒ",
            "äºŒä¸« â†” CLASSMATE_OF â†” å¼ ä¼Ÿ",
            "äºŒä¸« â†’ WORKS_AT â†’ åŒ—äº¬"
        ],
        notes="ç»ˆææµ‹è¯•ï¼šå¤šå®ä½“å¤šå…³ç³»",
    ),
]


def get_token() -> str:
    """è·å–è®¤è¯ token"""
    global TOKEN, USER_ID
    if TOKEN:
        return TOKEN
    
    resp = requests.post(f"{API_BASE}/auth/token", json={})
    if resp.status_code == 200:
        data = resp.json()
        TOKEN = data.get("access_token")
        USER_ID = data.get("user_id")
        print(f"âœ… è·å– Token æˆåŠŸ, user_id: {USER_ID}")
        return TOKEN
    else:
        print(f"âŒ è·å– Token å¤±è´¥: {resp.status_code}")
        return ""


def send_message(text: str) -> Dict[str, Any]:
    """å‘é€æ¶ˆæ¯å¹¶ç­‰å¾…å¤„ç†"""
    token = get_token()
    headers = {"Authorization": f"Bearer {token}"}
    
    # å‘é€ SSE æ¶ˆæ¯
    resp = requests.post(
        f"{API_BASE}/sse/message",
        json={"message": text},
        headers=headers,
        stream=True
    )
    
    memory_id = None
    full_response = ""
    
    for line in resp.iter_lines():
        if line:
            line_str = line.decode('utf-8')
            if line_str.startswith('data: '):
                data_str = line_str[6:]
                if data_str == '[DONE]':
                    break
                try:
                    event = json.loads(data_str)
                    if event.get('type') == 'text':
                        full_response += event.get('content', '')
                    elif event.get('type') == 'memory_pending':
                        memory_id = event.get('memory_id')
                except:
                    pass
    
    return {
        "memory_id": memory_id,
        "response": full_response
    }


def wait_for_memory_commit(memory_id: str, timeout: int = 30) -> bool:
    """ç­‰å¾… memory çŠ¶æ€å˜ä¸º committed"""
    token = get_token()
    headers = {"Authorization": f"Bearer {token}"}
    
    start = time.time()
    while time.time() - start < timeout:
        try:
            resp = requests.get(
                f"{API_BASE}/memories/{memory_id}",
                headers=headers
            )
            if resp.status_code == 200:
                data = resp.json()
                if data.get("status") == "committed":
                    return True
        except:
            pass
        time.sleep(2)
    
    return False


def get_graph() -> Dict[str, Any]:
    """è·å–å½“å‰å›¾è°±"""
    token = get_token()
    headers = {"Authorization": f"Bearer {token}"}
    
    resp = requests.get(f"{API_BASE}/graph/", headers=headers)
    if resp.status_code == 200:
        return resp.json()
    return {"nodes": [], "edges": []}


def analyze_graph(graph: Dict) -> Dict[str, Any]:
    """åˆ†æå›¾è°±å†…å®¹"""
    nodes = graph.get("nodes", [])
    edges = graph.get("edges", [])
    
    # æ„å»ºèŠ‚ç‚¹æ˜ å°„
    node_map = {n["id"]: n for n in nodes}
    
    # åˆ†æå®ä½“
    entities = []
    for n in nodes:
        if n.get("type") != "user":
            entities.append(f"{n.get('name', n['id'])}({n.get('type', 'unknown')})")
    
    # åˆ†æå…³ç³»
    relations = []
    for e in edges:
        source = node_map.get(e.get("source_id"), {})
        target = node_map.get(e.get("target_id"), {})
        source_name = source.get("name", e.get("source_id", "?"))
        target_name = target.get("name", e.get("target_id", "?"))
        rel_type = e.get("relation_type", "RELATED_TO")
        weight = e.get("current_weight") or e.get("weight", 1.0)
        relations.append(f"{source_name} â†’ {rel_type} â†’ {target_name} (w={weight:.2f})")
    
    return {
        "node_count": len(nodes),
        "edge_count": len(edges),
        "entities": entities,
        "relations": relations
    }


def run_test(test: TestCase) -> Dict[str, Any]:
    """è¿è¡Œå•ä¸ªæµ‹è¯•"""
    print(f"\n{'='*60}")
    print(f"æµ‹è¯• #{test.id} [{test.category}]")
    print(f"è¾“å…¥: {test.input_text}")
    if test.notes:
        print(f"å¤‡æ³¨: {test.notes}")
    print(f"{'='*60}")
    
    # è·å–æµ‹è¯•å‰çš„å›¾è°±
    graph_before = get_graph()
    analysis_before = analyze_graph(graph_before)
    
    # å‘é€æ¶ˆæ¯
    result = send_message(test.input_text)
    memory_id = result.get("memory_id")
    
    print(f"ğŸ“¤ æ¶ˆæ¯å·²å‘é€")
    print(f"ğŸ’¬ AI å›å¤: {result.get('response', '')[:100]}...")
    
    if memory_id:
        print(f"ğŸ”„ ç­‰å¾… Memory æäº¤ (id: {memory_id})...")
        committed = wait_for_memory_commit(memory_id)
        if committed:
            print(f"âœ… Memory å·²æäº¤")
        else:
            print(f"âš ï¸ Memory æäº¤è¶…æ—¶")
    else:
        print(f"â„¹ï¸ æ—  Memory ç”Ÿæˆ")
        time.sleep(3)  # ç­‰å¾…ä¸€ä¸‹
    
    # è·å–æµ‹è¯•åçš„å›¾è°±
    graph_after = get_graph()
    analysis_after = analyze_graph(graph_after)
    
    # è®¡ç®—æ–°å¢å†…å®¹
    new_entities = set(analysis_after["entities"]) - set(analysis_before["entities"])
    new_relations = set(analysis_after["relations"]) - set(analysis_before["relations"])
    
    print(f"\nğŸ“Š å›¾è°±å˜åŒ–:")
    print(f"  èŠ‚ç‚¹: {analysis_before['node_count']} â†’ {analysis_after['node_count']}")
    print(f"  è¾¹: {analysis_before['edge_count']} â†’ {analysis_after['edge_count']}")
    
    if new_entities:
        print(f"\nğŸ†• æ–°å¢å®ä½“:")
        for e in new_entities:
            print(f"    - {e}")
    
    if new_relations:
        print(f"\nğŸ”— æ–°å¢å…³ç³»:")
        for r in new_relations:
            print(f"    - {r}")
    
    # éªŒè¯æœŸæœ›
    print(f"\nğŸ“‹ æœŸæœ›éªŒè¯:")
    print(f"  æœŸæœ›å®ä½“: {test.expected_entities}")
    print(f"  æœŸæœ›å…³ç³»: {test.expected_relations}")
    
    return {
        "test_id": test.id,
        "input": test.input_text,
        "new_entities": list(new_entities),
        "new_relations": list(new_relations),
        "expected_entities": test.expected_entities,
        "expected_relations": test.expected_relations,
        "graph_after": analysis_after
    }


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "="*70)
    print("ğŸ§ª LLM + IR + Graph æ¶æ„éªŒè¯æµ‹è¯•")
    print("="*70)
    
    results = []
    
    for test in TEST_CASES:
        try:
            result = run_test(test)
            results.append(result)
        except Exception as e:
            print(f"âŒ æµ‹è¯• #{test.id} å¤±è´¥: {e}")
            results.append({
                "test_id": test.id,
                "error": str(e)
            })
        
        # æµ‹è¯•é—´éš”
        time.sleep(2)
    
    # æ±‡æ€»æŠ¥å‘Š
    print("\n" + "="*70)
    print("ğŸ“Š æµ‹è¯•æ±‡æ€»æŠ¥å‘Š")
    print("="*70)
    
    # è·å–æœ€ç»ˆå›¾è°±
    final_graph = get_graph()
    final_analysis = analyze_graph(final_graph)
    
    print(f"\næœ€ç»ˆå›¾è°±çŠ¶æ€:")
    print(f"  æ€»èŠ‚ç‚¹æ•°: {final_analysis['node_count']}")
    print(f"  æ€»è¾¹æ•°: {final_analysis['edge_count']}")
    
    print(f"\næ‰€æœ‰å®ä½“:")
    for e in final_analysis['entities']:
        print(f"    - {e}")
    
    print(f"\næ‰€æœ‰å…³ç³»:")
    for r in final_analysis['relations']:
        print(f"    - {r}")
    
    return results


if __name__ == "__main__":
    run_all_tests()
