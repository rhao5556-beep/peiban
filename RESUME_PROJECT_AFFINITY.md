# 简历项目：AI 陪伴记忆系统（Affinity Memory System）

## 项目背景与定位
面向“长期陪伴”场景，解决通用大模型在长周期使用中的两类核心问题：① 记忆遗忘导致反复确认、上下文断层；② 情感与偏好缺乏可对齐信号，关系难以稳定演进。项目以“可写入、可检索、可更新、可评测”为目标，落地分层记忆 + GraphRAG + 情感/偏好联动的端到端系统。

## 我的角色（可按实际删改）
- AI 产品策划（人机交互 + 系统设计），负责交互机制与记忆架构规划，推动端到端验证与迭代
- 协同算法/后端/前端定义数据结构、接口协议、评测指标与失败归因口径

## 技术与架构（简历“技术栈”）
- FastAPI + PostgreSQL（pgvector）+ Redis + Celery | Neo4j（记忆图谱）+ Milvus（向量）| React + TypeScript + SSE | KnowMeBench Dataset1 + LLM Judge

## 核心设计与落地（产品策划 + 交互 + 系统）
### 1) 设计“情感-记忆-偏好”三位一体机制：让关系可对齐、可控地演进
- 问题：仅存对话内容无法表达“哪些记忆对用户更重要/更敏感”，长期陪伴容易出现情感断层与不合时宜的回应
- 方案：引入好感度（Affinity）与健康边界信号，参与检索重排与主动触达决策；联动偏好设置（内容/主动消息/表情包等）形成闭环
- 结果：在产品体验上实现“越了解你、越懂边界”，同时为后续 A/B 与定向优化提供可量化信号入口

### 2) 规划分层记忆架构 + GraphRAG 混合检索：从“记住”到“会用”
- 问题：单纯向量检索容易“相似但不相关”，且难以支撑多跳关系推理与可解释证据
- 方案：分层记忆统一编排（working/context/episodic/long_term/profile）；混合检索 Vector（Milvus）+ Graph（Neo4j），并做四因子加权重排：语义相似度×0.4 + 图谱强度×0.3 + 好感度加成×0.2 + 时间新鲜度×0.1
- 结果：对“信息抽取/心身交互”等依赖证据的任务具备稳定收益，同时保留 graph_only（评测隔离）与 hybrid（真实体验）双模式

### 3) 建立记忆图谱可演化机制：可溯源、可衰减、可更新
- 问题：长期陪伴中“关系强度”随时间变化，过时信息不应持续占据高权重
- 方案：实体-关系模型支持 mention_count、provenance 溯源、updated_at 时间戳；关系强度引入时间衰减 exp(-decay_rate × days)，用于邻居扩展与排序
- 结果：图谱随互动动态生长与淡化，符合“记忆生长/遗忘”的长期使用规律

### 4) 工程保障与可观测：Outbox 一致性 + 评测可解释
- 问题：记忆写入涉及 PostgreSQL/Milvus/Neo4j 多存储，容易出现“写一半/不一致”，并影响评测归因
- 方案：Outbox 本地事务原子性（memories + outbox_events 同事务提交），Celery 后台消费写入多存储并推进状态；评测模式下用结构化错误区分“系统异常”与“能力不足”
- 结果：把失败面收敛到可重试的异步消费侧，并让评测产物可定位、可回归

## 评测与结果（可量化）
- KnowMeBench Dataset1（graph_only，每任务 3 题，共 21 题）：平均 **3.29/5（65.7%）**，**57.1%** 题目满分
- 分项亮点：Information Extraction、Mind-Body Interaction 均达到满分均值
- 评测复盘：补充 LoCoMo/KnowMeBench 的失败模式归因与可执行改进清单（弱项集中在时间粒度控制、Abstention 规则约束、心理分析短答案策略、非时间类结构化事实写入）

## 难点与取舍（面试常问）
- 为什么要 graph_only：将“检索/图谱能力”与“短期对话注入”物理隔离，保证评测可解释
- 为什么要 Outbox：把多存储一致性问题转为可重试的异步消费问题，避免在线链路被写入延迟或失败拖累
- 怎么做失败归因：评测模式提供结构化错误字段（error_code/trace_id/error_type），避免降级文案冒充模型回答

## 可选：面试追问备答（安全版）
### Q1：为什么好感度权重要设计成 0.2？
- 现阶段采用 0.2 作为初始权重，是基于产品假设：陪伴场景希望“相关且重要”的记忆优先出现，而不是只按语义相似度排序
- 工程上把权重做成可配置，后续用评测与线上行为数据做对比实验（ablation/网格搜索），避免拍脑袋

### Q2：沉默触发/主动触达怎么避免打扰？
- 采用开关 + 免打扰时段（quiet hours）+ 每日上限等硬约束，并把触达与关系状态/用户反馈联动，确保可控和可关闭
- 面试时优先强调“边界优先”：宁可少发，也不在用户不希望的时候介入

### Q3：3.29/5 怎么解释与怎么优化？
- 这是 graph_only 下的能力分，优势集中在信息抽取与证据依赖类任务；短板更多来自任务型规则（该拒答却推断、时间差值确定性计算、心理分析短答案模板等）
- 优化策略按“可控确定性优先”：先加任务类型 guard（Abstention 禁推断）、时间题走确定性计算，再对心理分析与事件排序做专门提示词/专门链路

## 2 分钟讲述稿（可直接背）
这个项目的目标是把“AI 陪伴”的长期记忆做成一个可迭代的系统，而不是只做一次性 Prompt。我们首先从产品问题出发：用户在长期陪伴里最痛的是记忆断层和情感/偏好不稳定，于是把系统拆成两条主链路：检索链路用 Milvus 向量 + Neo4j 图谱做混合检索，并用好感度与时间衰减做可控的检索偏置；写入链路用 Outbox + Celery 把多存储写入做成最终一致、可重试的后台任务，避免在线链路被拖慢或写一半。为了形成闭环，我们接入 KnowMeBench 做标准化评测，在 graph_only 模式下 21 题平均 3.29/5，并能按任务类型做失败归因与回归，持续迭代弱项能力。
