# LoCoMo è¯„æµ‹æ”¹è¿›æ–¹æ¡ˆ

**å½“å‰çŠ¶æ€**: 8.36% å‡†ç¡®ç‡ï¼ˆ1986 é¢˜ä¸­ä»… 166 é¢˜æ­£ç¡®ï¼‰  
**ç›®æ ‡**: æå‡åˆ° 40%+ å‡†ç¡®ç‡

---

## ğŸ”´ æ ¸å¿ƒé—®é¢˜åˆ†æ

### é—®é¢˜ 1: æ£€ç´¢å¤±è´¥ç‡ > 90%

**ç—‡çŠ¶**: å‡ ä¹æ‰€æœ‰å›ç­”éƒ½æ˜¯"æˆ‘æ²¡æœ‰è¶³å¤Ÿçš„ä¿¡æ¯"

**å¯èƒ½åŸå› **:
1. **è®°å¿†æœªå­˜å‚¨**: Outbox äº‹ä»¶æœªå¤„ç†ï¼Œè®°å¿†æœªå†™å…¥ Neo4j/Milvus
2. **æ£€ç´¢ç­–ç•¥å¤±æ•ˆ**: æŸ¥è¯¢ä¸è®°å¿†çš„ç›¸ä¼¼åº¦è®¡ç®—å¤±è´¥
3. **ä¸Šä¸‹æ–‡çª—å£å¤ªå°**: é•¿å¯¹è¯å†å²ä¸­çš„æ—©æœŸè®°å¿†è¢«é—å¿˜
4. **å®ä½“æå–å¤±è´¥**: å…³é”®å®ä½“æœªè¢«è¯†åˆ«å’Œå­˜å‚¨

### é—®é¢˜ 2: æ—¶é—´ç†è§£å´©æºƒï¼ˆ0.62%ï¼‰

**ç—‡çŠ¶**: æ—¶é—´ç›¸å…³é—®é¢˜å‡ ä¹å…¨é”™

**åŸå› **: ä¸ KnowMeBench ä¸€è‡´
- æ—¶é—´å®ä½“æå–ä¸å‡†ç¡®
- æ—¶é—´æ ¼å¼ä¸æ ‡å‡†åŒ–
- ç¼ºå°‘æ—¶é—´æ¨ç†èƒ½åŠ›

### é—®é¢˜ 3: äº‹å®å›å¿†å¤±è´¥ï¼ˆ1.06%ï¼‰

**ç—‡çŠ¶**: ç®€å•çš„äº‹å®é—®é¢˜éƒ½ç­”ä¸å‡ºæ¥

**åŸå› **:
- å®ä½“æå–é—æ¼å…³é”®ä¿¡æ¯
- å›¾è°±ä¸­ç¼ºå°‘å…³é”®èŠ‚ç‚¹
- æ£€ç´¢æœªå‘½ä¸­ç›¸å…³è®°å¿†

---

## ğŸ¯ ç´§æ€¥ä¿®å¤æ–¹æ¡ˆï¼ˆæœ¬å‘¨ï¼‰

### ä¿®å¤ 1: è¯Šæ–­å¹¶ä¿®å¤è®°å¿†å­˜å‚¨é“¾è·¯

**æ­¥éª¤ 1: è¿è¡Œè¯Šæ–­è„šæœ¬**
```bash
python diagnose_locomo_failure.py
```

**æ­¥éª¤ 2: æ£€æŸ¥ Celery Worker**
```bash
# æ£€æŸ¥ worker æ˜¯å¦è¿è¡Œ
docker ps | grep celery

# æŸ¥çœ‹ worker æ—¥å¿—
docker logs affinity-celery-worker --tail 100

# å¦‚æœæœªè¿è¡Œï¼Œå¯åŠ¨ worker
cd backend
celery -A app.worker worker --loglevel=info
```

**æ­¥éª¤ 3: æ£€æŸ¥ Outbox ç§¯å‹**
```bash
python backend/check_outbox_status.py
```

å¦‚æœæœ‰å¤§é‡å¾…å¤„ç†äº‹ä»¶ï¼Œæ‰‹åŠ¨è§¦å‘å¤„ç†:
```bash
python backend/app/worker/tasks/outbox.py
```


### ä¿®å¤ 2: å¢å¼ºæ£€ç´¢å¬å›ç‡

**é—®é¢˜**: å½“å‰æ£€ç´¢ç­–ç•¥å¯èƒ½è¿‡äºä¸¥æ ¼ï¼Œå¯¼è‡´å¬å›ç‡æä½

**è§£å†³æ–¹æ¡ˆ**: æ”¾å®½æ£€ç´¢é˜ˆå€¼ï¼Œå¢åŠ å¬å›æ•°é‡

**ä¿®æ”¹æ–‡ä»¶**: `backend/app/services/retrieval_service.py`

```python
# å½“å‰å¯èƒ½çš„é—®é¢˜
async def retrieve(self, query: str, top_k: int = 5):
    # é˜ˆå€¼å¯èƒ½å¤ªé«˜
    similarity_threshold = 0.8  # å¤ªä¸¥æ ¼ï¼
    
# æ”¹è¿›æ–¹æ¡ˆ
async def retrieve(self, query: str, top_k: int = 20):  # å¢åŠ å¬å›æ•°é‡
    # é™ä½é˜ˆå€¼
    similarity_threshold = 0.3  # æ›´å®½æ¾
    
    # å¤šç­–ç•¥æ£€ç´¢
    results = []
    
    # 1. å‘é‡æ£€ç´¢ï¼ˆè¯­ä¹‰ç›¸ä¼¼ï¼‰
    vector_results = await self.vector_search(query, top_k=10, threshold=0.3)
    results.extend(vector_results)
    
    # 2. å›¾æ£€ç´¢ï¼ˆå…³ç³»ç›¸å…³ï¼‰
    graph_results = await self.graph_search(query, top_k=10)
    results.extend(graph_results)
    
    # 3. å…³é”®è¯æ£€ç´¢ï¼ˆç²¾ç¡®åŒ¹é…ï¼‰
    keyword_results = await self.keyword_search(query, top_k=10)
    results.extend(keyword_results)
    
    # å»é‡å¹¶é‡æ’åº
    results = self.deduplicate_and_rerank(results, query)
    
    return results[:top_k]
```

**éªŒè¯**:
```bash
# æµ‹è¯•æ£€ç´¢å¬å›ç‡
python test_retrieval_recall.py
```

### ä¿®å¤ 3: å®ä½“æå–å¢å¼º

**é—®é¢˜**: å…³é”®å®ä½“æœªè¢«æå–ï¼Œå¯¼è‡´å›¾è°±ä¸å®Œæ•´

**è§£å†³æ–¹æ¡ˆ**: å¢å¼ºå®ä½“æå–çš„è¦†ç›–ç‡

**ä¿®æ”¹æ–‡ä»¶**: `backend/app/services/llm_extraction_service.py`

```python
ENTITY_EXTRACTION_PROMPT = """
ä»ä»¥ä¸‹å¯¹è¯ä¸­æå–æ‰€æœ‰å®ä½“å’Œå…³ç³»ã€‚

å¯¹è¯:
{conversation}

è¦æ±‚:
1. æå–æ‰€æœ‰äººç‰©ï¼ˆåŒ…æ‹¬åå­—ã€ä»£è¯ï¼‰
2. æå–æ‰€æœ‰åœ°ç‚¹ï¼ˆå›½å®¶ã€åŸå¸‚ã€è¡—é“ã€å»ºç­‘ï¼‰
3. æå–æ‰€æœ‰æ—¶é—´ï¼ˆæ—¥æœŸã€æ—¶é—´ç‚¹ã€æ—¶é—´æ®µï¼‰
4. æå–æ‰€æœ‰äº‹ä»¶ï¼ˆæ´»åŠ¨ã€è¡Œä¸ºã€è®¡åˆ’ï¼‰
5. æå–æ‰€æœ‰å±æ€§ï¼ˆèŒä¸šã€çˆ±å¥½ã€ç‰¹å¾ã€çŠ¶æ€ï¼‰
6. æå–æ‰€æœ‰å…³ç³»ï¼ˆå®¶åº­ã€æœ‹å‹ã€å·¥ä½œï¼‰

è¾“å‡ºæ ¼å¼:
{{
    "entities": [
        {{
            "name": "å®ä½“åç§°",
            "type": "PERSON/LOCATION/TIME/EVENT/ATTRIBUTE",
            "properties": {{"key": "value"}},
            "mentions": ["æåŠ1", "æåŠ2"]
        }}
    ],
    "relations": [
        {{
            "source": "å®ä½“1",
            "target": "å®ä½“2",
            "type": "å…³ç³»ç±»å‹",
            "properties": {{"key": "value"}}
        }}
    ]
}}

æ³¨æ„:
- ä¸è¦é—æ¼ä»»ä½•å®ä½“
- åŒä¸€å®ä½“çš„ä¸åŒæåŠè¦åˆå¹¶
- ä¿ç•™æ‰€æœ‰ç»†èŠ‚ä¿¡æ¯
"""
```

### ä¿®å¤ 4: æ—¶é—´å®ä½“æ ‡å‡†åŒ–

**é—®é¢˜**: æ—¶é—´æ ¼å¼ä¸ç»Ÿä¸€ï¼Œå¯¼è‡´æ—¶é—´æ¨ç†å¤±è´¥

**è§£å†³æ–¹æ¡ˆ**: ç»Ÿä¸€æ—¶é—´æ ¼å¼ä¸º ISO 8601

**æ–°å¢æœåŠ¡**: `backend/app/services/temporal_normalizer.py`

```python
from datetime import datetime
from dateutil import parser
import re

class TemporalNormalizer:
    """æ—¶é—´å®ä½“æ ‡å‡†åŒ–æœåŠ¡"""
    
    def normalize_time(self, time_str: str) -> dict:
        """
        æ ‡å‡†åŒ–æ—¶é—´å­—ç¬¦ä¸²
        
        è¾“å…¥: "7 May 2023", "2022", "The sunday before 25 May 2023"
        è¾“å‡º: {"iso": "2023-05-07", "precision": "day", "type": "point"}
        """
        result = {
            "original": time_str,
            "iso": None,
            "precision": None,  # year/month/day/hour/minute/second
            "type": None,  # point/range/relative
        }
        
        # å°è¯•è§£æç»å¯¹æ—¶é—´
        try:
            dt = parser.parse(time_str, fuzzy=True)
            result["iso"] = dt.isoformat()
            result["type"] = "point"
            
            # åˆ¤æ–­ç²¾åº¦
            if ":" in time_str:
                if re.search(r'\d{2}:\d{2}:\d{2}', time_str):
                    result["precision"] = "second"
                else:
                    result["precision"] = "minute"
            elif any(month in time_str.lower() for month in [
                "january", "february", "march", "april", "may", "june",
                "july", "august", "september", "october", "november", "december"
            ]):
                result["precision"] = "day"
            elif re.search(r'\d{4}', time_str):
                result["precision"] = "year"
                
        except:
            # ç›¸å¯¹æ—¶é—´
            result["type"] = "relative"
            result["reference"] = self.extract_reference_time(time_str)
        
        return result
    
    def extract_reference_time(self, time_str: str) -> str:
        """æå–ç›¸å¯¹æ—¶é—´çš„å‚è€ƒç‚¹"""
        # "The sunday before 25 May 2023" -> "2023-05-25"
        match = re.search(r'\d{1,2}\s+\w+\s+\d{4}', time_str)
        if match:
            return parser.parse(match.group()).isoformat()
        return None
```

---

## ğŸ“Š ä¸­æœŸä¼˜åŒ–æ–¹æ¡ˆï¼ˆ2-4 å‘¨ï¼‰

### ä¼˜åŒ– 1: é•¿å¯¹è¯å†å²ç®¡ç†

**é—®é¢˜**: LoCoMo æœ‰ 1986 ä¸ªé—®é¢˜ï¼Œè·¨è¶Šé•¿æ—¶é—´çš„å¯¹è¯å†å²

**è§£å†³æ–¹æ¡ˆ**: å®ç°åˆ†å±‚è®°å¿†ç®¡ç†

```python
class HierarchicalMemoryManager:
    """åˆ†å±‚è®°å¿†ç®¡ç†å™¨"""
    
    async def store_memory(self, memory: dict):
        """
        æ ¹æ®é‡è¦æ€§å’Œæ—¶é—´åˆ†å±‚å­˜å‚¨è®°å¿†
        
        å±‚çº§:
        - å·¥ä½œè®°å¿† (Working Memory): æœ€è¿‘ 10 æ¡å¯¹è¯
        - çŸ­æœŸè®°å¿† (Short-term): æœ€è¿‘ 100 æ¡å¯¹è¯
        - é•¿æœŸè®°å¿† (Long-term): æ‰€æœ‰å†å²å¯¹è¯
        """
        # è®¡ç®—é‡è¦æ€§åˆ†æ•°
        importance = await self.calculate_importance(memory)
        
        # å­˜å‚¨åˆ°ä¸åŒå±‚çº§
        await self.working_memory.add(memory)
        
        if importance > 0.5:
            await self.short_term_memory.add(memory)
        
        if importance > 0.7 or self.is_factual(memory):
            await self.long_term_memory.add(memory)
    
    async def retrieve_hierarchical(self, query: str):
        """åˆ†å±‚æ£€ç´¢"""
        results = []
        
        # 1. ä¼˜å…ˆä»å·¥ä½œè®°å¿†æ£€ç´¢ï¼ˆæœ€ç›¸å…³ï¼‰
        results.extend(await self.working_memory.search(query, top_k=5))
        
        # 2. ä»çŸ­æœŸè®°å¿†æ£€ç´¢
        if len(results) < 10:
            results.extend(await self.short_term_memory.search(query, top_k=10))
        
        # 3. ä»é•¿æœŸè®°å¿†æ£€ç´¢ï¼ˆäº‹å®æ€§ä¿¡æ¯ï¼‰
        if len(results) < 15:
            results.extend(await self.long_term_memory.search(query, top_k=10))
        
        return self.deduplicate(results)
```

### ä¼˜åŒ– 2: å®ä½“é“¾æ¥ä¸æ¶ˆæ­§

**é—®é¢˜**: åŒä¸€å®ä½“çš„ä¸åŒæåŠæœªèƒ½å…³è”

**è§£å†³æ–¹æ¡ˆ**: å®ä½“é“¾æ¥æœåŠ¡

```python
class EntityLinker:
    """å®ä½“é“¾æ¥æœåŠ¡"""
    
    async def link_entities(self, entities: List[dict]):
        """
        é“¾æ¥åŒä¸€å®ä½“çš„ä¸åŒæåŠ
        
        ä¾‹å¦‚:
        - "Caroline" å’Œ "å¥¹" æŒ‡å‘åŒä¸€äºº
        - "Sweden" å’Œ "ç‘å…¸" æ˜¯åŒä¸€åœ°ç‚¹
        """
        linked = []
        
        for entity in entities:
            # æŸ¥æ‰¾å·²å­˜åœ¨çš„å®ä½“
            existing = await self.find_existing_entity(entity)
            
            if existing:
                # åˆå¹¶åˆ°å·²å­˜åœ¨å®ä½“
                await self.merge_entity(existing, entity)
                linked.append(existing)
            else:
                # åˆ›å»ºæ–°å®ä½“
                new_entity = await self.create_entity(entity)
                linked.append(new_entity)
        
        return linked
    
    async def find_existing_entity(self, entity: dict):
        """æŸ¥æ‰¾å·²å­˜åœ¨çš„å®ä½“"""
        # 1. ç²¾ç¡®åŒ¹é…
        exact_match = await self.exact_match(entity["name"])
        if exact_match:
            return exact_match
        
        # 2. æ¨¡ç³ŠåŒ¹é…
        fuzzy_matches = await self.fuzzy_match(entity["name"])
        if fuzzy_matches:
            return self.select_best_match(fuzzy_matches, entity)
        
        # 3. è¯­ä¹‰åŒ¹é…
        semantic_matches = await self.semantic_match(entity)
        if semantic_matches:
            return self.select_best_match(semantic_matches, entity)
        
        return None
```


### ä¼˜åŒ– 3: å¤šè·³æ¨ç†æ”¯æŒ

**é—®é¢˜**: å¤æ‚é—®é¢˜éœ€è¦å¤šæ­¥æ¨ç†

**è§£å†³æ–¹æ¡ˆ**: å®ç°å¤šè·³æ£€ç´¢å’Œæ¨ç†

```python
class MultiHopReasoner:
    """å¤šè·³æ¨ç†å™¨"""
    
    async def reason(self, question: str, max_hops: int = 3):
        """
        å¤šè·³æ¨ç†
        
        ä¾‹å¦‚:
        é—®é¢˜: "Caroline 4 å¹´å‰ä»å“ªé‡Œæ¬æ¥ï¼Ÿ"
        
        Hop 1: æ£€ç´¢ "Caroline æ¬å®¶" -> æ‰¾åˆ° "Caroline ä» Sweden æ¬æ¥"
        Hop 2: æ£€ç´¢ "Caroline Sweden æ—¶é—´" -> æ‰¾åˆ° "4 years ago"
        Hop 3: ç»¼åˆä¿¡æ¯ -> ç­”æ¡ˆ: "Sweden"
        """
        context = []
        current_query = question
        
        for hop in range(max_hops):
            # æ£€ç´¢å½“å‰æŸ¥è¯¢
            results = await self.retrieve(current_query, top_k=10)
            context.extend(results)
            
            # åˆ¤æ–­æ˜¯å¦æœ‰è¶³å¤Ÿä¿¡æ¯
            has_answer, confidence = await self.check_sufficiency(
                question, context
            )
            
            if has_answer and confidence > 0.8:
                break
            
            # ç”Ÿæˆä¸‹ä¸€è·³æŸ¥è¯¢
            current_query = await self.generate_next_query(
                question, context
            )
        
        # ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
        answer = await self.generate_answer(question, context)
        return answer
```

---

## ğŸ¯ é¢„æœŸæ”¹è¿›æ•ˆæœ

| é˜¶æ®µ | æªæ–½ | é¢„æœŸå‡†ç¡®ç‡ | æå‡ |
|------|------|-----------|------|
| å½“å‰ | - | 8.36% | - |
| ç´§æ€¥ä¿®å¤ï¼ˆ1å‘¨ï¼‰ | ä¿®å¤å­˜å‚¨é“¾è·¯ + å¢å¼ºæ£€ç´¢ | 25%+ | +17% |
| ä¸­æœŸä¼˜åŒ–ï¼ˆ1æœˆï¼‰ | åˆ†å±‚è®°å¿† + å®ä½“é“¾æ¥ | 40%+ | +15% |
| é•¿æœŸä¼˜åŒ–ï¼ˆ3æœˆï¼‰ | å¤šè·³æ¨ç† + æ—¶é—´æ¨ç† | 55%+ | +15% |

### å„ç±»åˆ«é¢„æœŸæå‡

| ç±»åˆ« | å½“å‰ | 1å‘¨å | 1æœˆå | 3æœˆå |
|------|------|-------|-------|-------|
| äº‹å®å›å¿† | 1.06% | 20% | 40% | 60% |
| æ—¶é—´ç†è§£ | 0.62% | 10% | 25% | 45% |
| æ¨ç†ä¸æ¨æ–­ | 2.08% | 15% | 35% | 50% |
| ç»†èŠ‚ç†è§£ | 0.83% | 18% | 38% | 55% |
| **å¹³å‡** | **8.36%** | **25%** | **40%** | **55%** |

---

## ğŸš€ ç«‹å³è¡ŒåŠ¨æ¸…å•

### ä»Šå¤©ï¼ˆå¿…åšï¼‰

1. **è¿è¡Œè¯Šæ–­è„šæœ¬**
   ```bash
   python diagnose_locomo_failure.py
   ```

2. **æ£€æŸ¥ Celery Worker çŠ¶æ€**
   ```bash
   docker ps | grep celery
   docker logs affinity-celery-worker --tail 100
   ```

3. **æ£€æŸ¥ Outbox ç§¯å‹**
   ```bash
   python backend/check_outbox_status.py
   ```

4. **å¦‚æœå‘ç°é—®é¢˜ï¼Œé‡æ–°åŒæ­¥è®°å¿†**
   ```bash
   python backend/resync_memories_to_neo4j.py
   ```

### æœ¬å‘¨ï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰

1. **é™ä½æ£€ç´¢é˜ˆå€¼**
   - ä¿®æ”¹ `retrieval_service.py`
   - ä» 0.8 é™åˆ° 0.3
   - å¢åŠ  top_k ä» 5 åˆ° 20

2. **å¢å¼ºå®ä½“æå–**
   - ä¿®æ”¹ `llm_extraction_service.py`
   - ä½¿ç”¨æ›´è¯¦ç»†çš„æå– prompt
   - ç¡®ä¿ä¸é—æ¼å…³é”®å®ä½“

3. **æ·»åŠ æ—¶é—´æ ‡å‡†åŒ–**
   - åˆ›å»º `temporal_normalizer.py`
   - ç»Ÿä¸€æ—¶é—´æ ¼å¼ä¸º ISO 8601
   - ä¿ç•™æ—¶é—´ç²¾åº¦ä¿¡æ¯

4. **éªŒè¯æ”¹è¿›æ•ˆæœ**
   ```bash
   # é‡æ–°è¿è¡Œ LoCoMo è¯„æµ‹ï¼ˆå°è§„æ¨¡ï¼‰
   python evals/run_full_locomo_pipeline.py --limit 100
   ```

### ä¸‹å‘¨ï¼ˆä¸­ä¼˜å…ˆçº§ï¼‰

1. **å®ç°åˆ†å±‚è®°å¿†ç®¡ç†**
2. **æ·»åŠ å®ä½“é“¾æ¥æœåŠ¡**
3. **ä¼˜åŒ–æ£€ç´¢ç­–ç•¥**
4. **è¿è¡Œå®Œæ•´ LoCoMo è¯„æµ‹**

---

## ğŸ“Š ç›‘æ§æŒ‡æ ‡

### å…³é”®æŒ‡æ ‡

1. **æ£€ç´¢å¬å›ç‡**
   - ç›®æ ‡: ä» < 10% æå‡åˆ° 60%+
   - æµ‹é‡: æ£€ç´¢åˆ°ç›¸å…³è®°å¿†çš„æ¯”ä¾‹

2. **å®ä½“è¦†ç›–ç‡**
   - ç›®æ ‡: ä» ? æå‡åˆ° 80%+
   - æµ‹é‡: æå–çš„å®ä½“ / åº”æå–çš„å®ä½“

3. **Outbox å¤„ç†å»¶è¿Ÿ**
   - ç›®æ ‡: P50 < 2s, P95 < 30s
   - æµ‹é‡: äº‹ä»¶åˆ›å»ºåˆ°å¤„ç†å®Œæˆçš„æ—¶é—´

4. **å„ç±»åˆ«å‡†ç¡®ç‡**
   - äº‹å®å›å¿†: 1.06% â†’ 20%+
   - æ—¶é—´ç†è§£: 0.62% â†’ 10%+
   - æ¨ç†ä¸æ¨æ–­: 2.08% â†’ 15%+
   - ç»†èŠ‚ç†è§£: 0.83% â†’ 18%+

---

## ğŸ’¡ å…³é”®æ´å¯Ÿ

### ä¸ºä»€ä¹ˆ LoCoMo æ¯” KnowMeBench å·®è¿™ä¹ˆå¤šï¼Ÿ

1. **æ•°æ®é‡å·®å¼‚**
   - KnowMeBench: 21 é¢˜ï¼ˆå¿«é€Ÿæµ‹è¯•ï¼‰
   - LoCoMo: 1986 é¢˜ï¼ˆé•¿å¯¹è¯å†å²ï¼‰

2. **ä»»åŠ¡å¤æ‚åº¦**
   - KnowMeBench: çŸ­ä¸Šä¸‹æ–‡ï¼Œæ˜ç¡®é—®é¢˜
   - LoCoMo: é•¿å¯¹è¯å†å²ï¼Œéœ€è¦è·¨å¤šè½®å¯¹è¯æ£€ç´¢

3. **ç³»ç»Ÿç“¶é¢ˆ**
   - KnowMeBench æš´éœ²äº† prompt å’Œæ¨ç†é—®é¢˜
   - LoCoMo æš´éœ²äº†å­˜å‚¨å’Œæ£€ç´¢çš„æ ¹æœ¬é—®é¢˜

### æ ¸å¿ƒé—®é¢˜

**LoCoMo çš„ 8.36% å‡†ç¡®ç‡è¯´æ˜ä½ çš„ç³»ç»Ÿåœ¨é•¿æœŸè®°å¿†å­˜å‚¨å’Œæ£€ç´¢ä¸Šå­˜åœ¨æ ¹æœ¬æ€§é—®é¢˜ï¼**

è¿™ä¸æ˜¯ prompt ä¼˜åŒ–èƒ½è§£å†³çš„ï¼Œéœ€è¦ï¼š
1. ä¿®å¤è®°å¿†å­˜å‚¨é“¾è·¯
2. å¤§å¹…æå‡æ£€ç´¢å¬å›ç‡
3. å®ç°çœŸæ­£çš„é•¿æœŸè®°å¿†ç®¡ç†

---

## ğŸ“ Git æäº¤å»ºè®®

```bash
# ç´§æ€¥ä¿®å¤
git commit -m "Fix: ä¿®å¤è®°å¿†å­˜å‚¨é“¾è·¯ï¼Œç¡®ä¿ Outbox æ­£å¸¸å¤„ç†"
git commit -m "Fix: é™ä½æ£€ç´¢é˜ˆå€¼ï¼Œæå‡å¬å›ç‡"
git commit -m "Add: å¢å¼ºå®ä½“æå–è¦†ç›–ç‡"
git commit -m "Add: æ—¶é—´å®ä½“æ ‡å‡†åŒ–æœåŠ¡"

# ä¸­æœŸä¼˜åŒ–
git commit -m "Add: åˆ†å±‚è®°å¿†ç®¡ç†ç³»ç»Ÿ"
git commit -m "Add: å®ä½“é“¾æ¥ä¸æ¶ˆæ­§æœåŠ¡"
git commit -m "Add: å¤šè·³æ¨ç†æ”¯æŒ"

# éªŒè¯
git commit -m "Test: LoCoMo è¯„æµ‹å‡†ç¡®ç‡æå‡åˆ° 25%+"
```

---

**æ€»ç»“**: LoCoMo çš„æä½å‡†ç¡®ç‡ï¼ˆ8.36%ï¼‰æš´éœ²äº†ç³»ç»Ÿåœ¨é•¿æœŸè®°å¿†ç®¡ç†ä¸Šçš„æ ¹æœ¬é—®é¢˜ã€‚ä¼˜å…ˆä¿®å¤å­˜å‚¨é“¾è·¯å’Œæ£€ç´¢å¬å›ç‡ï¼Œé¢„æœŸ 1 å‘¨å†…å¯æå‡åˆ° 25%+ï¼Œ1 ä¸ªæœˆå†…è¾¾åˆ° 40%+ã€‚
